{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99230e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to Python path to allow module imports\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from src.utils.forecasting import forecast_and_evaluate\n",
    "from src.utils.cluster_zone import cluster_zones_with_kpi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c8be99",
   "metadata": {},
   "source": [
    "## Forecast and evaluate\n",
    "**Objective:** Apply time series forecasting and evaluation to the cleaned January data using the `forecast_and_evaluate` function (from `src.utils.forecasting`).\n",
    "* **Hourly forecasting:** Forecast trip data at hourly frequency ('H') with 168 test periods and ARIMA order (1, 0, 1), then display metrics and predictions.\n",
    "* **Daily forecasting:** Forecast at daily frequency ('D') with 7 test periods and the same ARIMA order, then display metrics and predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f05567",
   "metadata": {},
   "source": [
    "# Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25eade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_parquet(\"../processed/cleaned_data/cleaned_yellow_tripdata_2021-01.parquet\")\n",
    "\n",
    "df1_forecast_hourly = forecast_and_evaluate(\n",
    "    df1=df1,\n",
    "    freq='H',\n",
    "    test_periods= 168,\n",
    "    arima_order=(1, 0, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc831bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_forecast_hourly['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ff259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_forecast_hourly['predictions']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b95527d",
   "metadata": {},
   "source": [
    "# Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c0b669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_forecast_daily = forecast_and_evaluate(\n",
    "    df1=df1,\n",
    "    freq='D',\n",
    "    test_periods=7,        # 7 ngày test\n",
    "    arima_order=(1, 0, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e23ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_forecast_daily['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a07290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_forecast_daily['predictions']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c142e3",
   "metadata": {},
   "source": [
    "## Cluster Zones by Temporal–KPI Patterns\n",
    "**Objective:** Group taxi zones into homogeneous clusters based on their temporal demand and performance characteristics using unsupervised learning.\n",
    "\n",
    "* **Data Aggregation:** Aggregate trip-level data at the *zone–time-bin* level (zone × hour / time window), computing key KPIs such as number of trips, median (p50) and tail (p95) trip duration, and demand index.\n",
    "* **Feature Construction:** Represent each zone by a KPI vector capturing its typical operational pattern across time (e.g., rush-hour intensity, variability, and extreme congestion behavior).\n",
    "* **Normalization:** Apply feature scaling (e.g., standardization) to ensure all KPIs contribute comparably to the distance metric used in clustering.\n",
    "* **Clustering Method:** Use **K-means clustering** to partition zones into groups with similar demand–performance profiles.\n",
    "* **Cluster Interpretation:** Assign semantic labels to clusters (e.g., *High-demand core*, *Rush-hour dominant*, *Low-activity peripheral*) based on centroid characteristics and temporal patterns.\n",
    "* **Analytical Purpose:** Enable comparative analysis across zone types, support operational insights, and provide a structured basis for downstream tasks such as forecasting, anomaly detection, or policy evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098bc950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform integrated clustering\n",
    "qa_flags = pd.read_parquet(\"../processed/flags_for_analysis/flag_yellow_tripdata_2021-01.parquet\")\n",
    "clustered_df = cluster_zones_with_kpi(df1, qa_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6efc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_df[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c10a3",
   "metadata": {},
   "source": [
    "# Cluster zone 12 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d9c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directory\n",
    "output_dir = \"../processed/cluster_zone\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate month list from 01 to 12\n",
    "months = [f\"{i:02d}\" for i in range(1, 13)]\n",
    "\n",
    "for month in months:\n",
    "    output_path = os.path.join(output_dir, f\"clustered_yellow_tripdata_2021-{month}.parquet\")\n",
    "    \n",
    "    # Skip processing if the output file already exists\n",
    "    if os.path.exists(output_path):\n",
    "        continue\n",
    "\n",
    "    # Only log and process if file is missing\n",
    "    print(f\"Processing month {month}...\")\n",
    "    \n",
    "    # Load input datasets\n",
    "    df_path = f\"../processed/cleaned_data/cleaned_yellow_tripdata_2021-{month}.parquet\"\n",
    "    qa_path = f\"../processed/flags_for_analysis/flag_yellow_tripdata_2021-{month}.parquet\"\n",
    "    \n",
    "    df1 = pd.read_parquet(df_path)\n",
    "    qa_flags = pd.read_parquet(qa_path)\n",
    "    \n",
    "    # Execute clustering algorithm\n",
    "    clustered_df, centroids = cluster_zones_with_kpi(df1, qa_flags)\n",
    "    \n",
    "    # Save results to parquet\n",
    "    clustered_df.to_parquet(output_path)\n",
    "    \n",
    "    print(f\"Successfully processed and saved month {month}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
