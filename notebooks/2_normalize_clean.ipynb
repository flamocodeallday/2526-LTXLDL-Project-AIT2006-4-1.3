{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28f44e98",
   "metadata": {},
   "source": [
    "# NORMALIZE AND CLEAN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb54f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to Python path to allow module imports\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import custom utility functions for data processing\n",
    "from src.utils.normalizing import normalize          # Standardize or scale data\n",
    "from src.utils.qa_rules import run_quality_check, summarize_qa_flags  # Apply and summarize QA rules\n",
    "from src.utils.cleaning import clean                 # Perform data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ca6d96",
   "metadata": {},
   "source": [
    "## Normalize Data of a month using built functions\n",
    "**Objective:** Load the raw January data and apply the `normalize` function (from `src.utils.normalizing`).\n",
    "* **Enrich data:** Add `PU/DO_Borough`, `payment_type_name`, etc.\n",
    "* **Feature Engineering:** Create derived columns like `trip_duration`, `avg_speed`, and `pickup_day_of_week`.\n",
    "* **Feature Selection:** Drop irrelevant columns identified in Notebook 1, specifically 'airport_fee' since it has only 5 nonnull values; 'store_and_fwd_flag', 'VendorID' because they are irrelevant to analysis; 'mta_tax','improvement_surcharge' due to their low variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d3757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_parquet(\"../raw/yellow_tripdata_2021-01.parquet\")\n",
    "df1_normalized = normalize(df1)\n",
    "print(\"Successfully normalized January data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8223ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 10 rows of data before normalized: \")\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2226d186",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 10 rows of data after normalized with new columns at the end: \")\n",
    "df1_normalized.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fdc92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data after normalized info: \")\n",
    "df1_normalized.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a980a574",
   "metadata": {},
   "source": [
    "## Applying QA steps \n",
    "**Objective:** Apply the `run_quality_check` function (from `src.utils.qa_rules`) to the normalized data.\n",
    "* This will return `df1_flag`, a DataFrame containing 11 boolean flag columns based on 11 rules.\n",
    "* Then, use `summarize_qa_flags` to generate the summary string (\"count/pct%\") for the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36ce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_flag = run_quality_check(df1_normalized)\n",
    "january = summarize_qa_flags(df1_flag)\n",
    "print(\"Successfully run quality check!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16df144",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 10 rows of January's flag: \")\n",
    "df1_flag.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3547eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary of January's flag, 0-10 indicates rule ID, row 11 is the sum of trips that has violations: \")\n",
    "january"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6278414",
   "metadata": {},
   "source": [
    "## Clean Data of a month using built function\n",
    "**Objective:** Apply the `clean` function (from `src.utils.cleaning`).\n",
    "* This function will take `df1_normalized` and `df1_flag` as input.\n",
    "* It will filter and remove rows that violate the rules according to our defined strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7922c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_cleaned, df1_standard = clean(df1_normalized, df1_flag)\n",
    "print(\"Successfully cleaned data!\")\n",
    "print(\"Cleaned data has shape: \", df1_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab496f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data after cleaned info: \")\n",
    "df1_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77670a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"More information about cleaned data (numerical values):\")\n",
    "df1_cleaned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7862279d",
   "metadata": {},
   "source": [
    "## Clean Data of 12 months and save it to processed\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
